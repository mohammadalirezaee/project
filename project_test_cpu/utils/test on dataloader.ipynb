{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('D:/AmirKabir/tez/ewap_dataset/ewap_dataset/seq_hotel/seq_hotel.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19350"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('D:/AmirKabir/tez/ewap_dataset/ewap_dataset/seq_hotel/seq_hotel.avi')\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture('D:/AmirKabir/tez/ewap_dataset/ewap_dataset/seq_hotel/seq_hotel.avi')\n",
    "# Set the frame position to 10\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 19260)\n",
    "\n",
    "# Read the frame at position 10\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Check if the frame is valid\n",
    "if ret:\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame 11', frame)\n",
    "    cv2.waitKey(0)\n",
    "else:\n",
    "    print(\"Error reading frame\")\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def get_dataloader(data_dir, phase, obs_len, pred_len, batch_size):\n",
    "    r\"\"\"Get dataloader for a specific phase\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): path to the dataset directory\n",
    "        phase (str): phase of the data, one of 'train', 'val', 'test'\n",
    "        obs_len (int): length of observed trajectory\n",
    "        pred_len (int): length of predicted trajectory\n",
    "        batch_size (int): batch size\n",
    "\n",
    "    Returns:\n",
    "        loader_phase (torch.utils.data.DataLoader): dataloader for the specific phase\n",
    "    \"\"\"\n",
    "\n",
    "    assert phase in ['train', 'val', 'test']\n",
    "    \n",
    "    \n",
    "    data_set = data_dir + '/' + phase + '/'\n",
    "    shuffle = True if phase == 'train' else False\n",
    "    drop_last = True if phase == 'train' else False\n",
    "    frame_path = data_dir \n",
    "    dataset_phase = TrajectoryDataset(data_set,frame_path = frame_path ,obs_len=obs_len, pred_len=pred_len)\n",
    "    sampler_phase = None\n",
    "    if batch_size > 1:\n",
    "        sampler_phase = TrajBatchSampler(dataset_phase, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    loader_phase = DataLoader(dataset_phase, batch_sampler=sampler_phase ,collate_fn=traj_collate_fn, pin_memory=True)\n",
    "    return loader_phase\n",
    "\n",
    "\n",
    "def traj_collate_fn(data):\n",
    "    r\"\"\"Collate function for the dataloader\n",
    "\n",
    "    Args:\n",
    "        data (list): list of tuples of (obs_seq, pred_seq, non_linear_ped, loss_mask, seq_start_end)\n",
    "\n",
    "    Returns:\n",
    "        obs_seq_list (torch.Tensor): (num_ped, obs_len, 2)\n",
    "        pred_seq_list (torch.Tensor): (num_ped, pred_len, 2)\n",
    "        non_linear_ped_list (torch.Tensor): (num_ped,)\n",
    "        loss_mask_list (torch.Tensor): (num_ped, obs_len + pred_len)\n",
    "        scene_mask (torch.Tensor): (num_ped, num_ped)\n",
    "        seq_start_end (torch.Tensor): (num_ped, 2)\n",
    "        frame_list_tensor\n",
    "    \"\"\"\n",
    "\n",
    "    obs_seq_list, pred_seq_list, non_linear_ped_list, loss_mask_list, _,frame_list_tensor= zip(*data)\n",
    "\n",
    "    _len = [len(seq) for seq in obs_seq_list]\n",
    "    cum_start_idx = [0] + np.cumsum(_len).tolist()\n",
    "    seq_start_end = [[start, end] for start, end in zip(cum_start_idx, cum_start_idx[1:])]\n",
    "    seq_start_end = torch.LongTensor(seq_start_end)\n",
    "    scene_mask = torch.zeros(sum(_len), sum(_len), dtype=torch.bool)\n",
    "    for idx, (start, end) in enumerate(seq_start_end):\n",
    "        scene_mask[start:end, start:end] = 1\n",
    "\n",
    "    out = [torch.cat(obs_seq_list, dim=0), torch.cat(pred_seq_list, dim=0),\n",
    "           torch.cat(non_linear_ped_list, dim=0), torch.cat(loss_mask_list, dim=0), scene_mask, seq_start_end,frame_list_tensor]\n",
    "    return tuple(out)\n",
    "\n",
    "\n",
    "class TrajBatchSampler(Sampler):\n",
    "    r\"\"\"Samples batched elements by yielding a mini-batch of indices.\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "        batch_size (int): Size of mini-batch.\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "            at every epoch (default: ``False``).\n",
    "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
    "            its size would be less than ``batch_size``\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, batch_size=64, shuffle=False, drop_last=False, generator=None):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.generator = generator\n",
    "\n",
    "    def __iter__(self):\n",
    "        assert len(self.data_source) == len(self.data_source.num_peds_in_seq)\n",
    "\n",
    "        if self.shuffle:\n",
    "            if self.generator is None:\n",
    "                generator = torch.Generator()\n",
    "                generator.manual_seed(int(torch.empty((), dtype=torch.int64).random_().item()))\n",
    "            else:\n",
    "                generator = self.generator\n",
    "            indices = torch.randperm(len(self.data_source), generator=generator).tolist()\n",
    "        else:\n",
    "            indices = list(range(len(self.data_source)))\n",
    "        num_peds_indices = self.data_source.num_peds_in_seq[indices]\n",
    "\n",
    "        batch = []\n",
    "        total_num_peds = 0\n",
    "        for idx, num_peds in zip(indices, num_peds_indices):\n",
    "            batch.append(idx)\n",
    "            total_num_peds += num_peds\n",
    "            if total_num_peds >= self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                total_num_peds = 0\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        # Approximated number of batches.\n",
    "        # The order of trajectories can be shuffled, so this number can vary from run to run.\n",
    "        if self.drop_last:\n",
    "            return sum(self.data_source.num_peds_in_seq) // self.batch_size\n",
    "        else:\n",
    "            return (sum(self.data_source.num_peds_in_seq) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "\n",
    "def read_file(_path, delim='\\t'):\n",
    "    data = []\n",
    "    if delim == 'tab':\n",
    "        delim = '\\t'\n",
    "    elif delim == 'space':\n",
    "        delim = ' '\n",
    "    with open(_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(delim)\n",
    "            line = [float(i) for i in line]\n",
    "            data.append(line)\n",
    "    return np.asarray(data)\n",
    "\n",
    "\n",
    "def poly_fit(traj, traj_len, threshold):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - traj: Numpy array of shape (2, traj_len)\n",
    "    - traj_len: Len of trajectory\n",
    "    - threshold: Minimum error to be considered for non-linear traj\n",
    "    Output:\n",
    "    - int: 1 -> Non Linear 0-> Linear\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, traj_len - 1, traj_len)\n",
    "    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1]\n",
    "    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1]\n",
    "    if res_x + res_y >= threshold:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def prepare_image(frame):\n",
    "    transform = transforms.Compose([\n",
    "                      transforms.ToPILImage(),\n",
    "                      transforms.Resize(300),\n",
    "                      transforms.ToTensor()])\n",
    "    transformed_image = transform(frame)\n",
    "    transformed_image = transformed_image.unsqueeze(0)\n",
    "    return transformed_image.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# In your TrajectoryDataset class\n",
    "\n",
    "\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    \"\"\"Dataloder for the Trajectory datasets\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir,frame_path ,obs_len=8, pred_len=12, skip=1, threshold=0.02, min_ped=1, delim='\\t'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - data_dir: Directory containing dataset files in the format <frame_id> <ped_id> <x> <y>\n",
    "        - obs_len: Number of time-steps in input trajectories\n",
    "        - pred_len: Number of time-steps in output trajectories\n",
    "        - skip: Number of frames to skip while making the dataset\n",
    "        - threshold: Minimum error to be considered for non-linear traj when using a linear predictor\n",
    "        - min_ped: Minimum number of pedestrians that should be in a sequence\n",
    "        - delim: Delimiter in the dataset files\n",
    "        \"\"\"\n",
    "        super(TrajectoryDataset, self).__init__()\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.skip = skip\n",
    "        self.seq_len = self.obs_len + self.pred_len\n",
    "        self.delim = delim\n",
    "        self.frame_path = frame_path\n",
    "        self.video_path = os.path.join(self.frame_path, 'seq_hotel.avi')\n",
    "\n",
    "        all_files = os.listdir(self.data_dir)\n",
    "        all_files = [os.path.join(self.data_dir, _path) for _path in all_files]\n",
    "        num_peds_in_seq = []\n",
    "        seq_list = []\n",
    "        loss_mask_list = []\n",
    "        non_linear_ped = []\n",
    "        pedestrain_id = []#new add\n",
    "        for path in all_files:\n",
    "            \n",
    "            try:\n",
    "                data = read_file(path, delim)\n",
    "            except:\n",
    "                data = read_file(path, delim = 'space')\n",
    "            frame_id = [] #new add    \n",
    "            frames = np.unique(data[:, 0]).tolist()\n",
    "            frame_data = []\n",
    "            for frame in frames:\n",
    "                frame_data.append(data[frame == data[:, 0], :])\n",
    "            num_sequences = int(math.ceil((len(frames) - self.seq_len + 1) / skip))\n",
    "\n",
    "            for idx in range(0, num_sequences * self.skip + 1, skip):\n",
    "                curr_seq_data = np.concatenate(frame_data[idx:idx + self.seq_len], axis=0)\n",
    "                frame_range = np.unique(curr_seq_data[:, 0])       #new add\n",
    "                peds_in_curr_seq = np.unique(curr_seq_data[:, 1])\n",
    "                curr_seq = np.zeros((len(peds_in_curr_seq), 2, self.seq_len))\n",
    "                curr_loss_mask = np.zeros((len(peds_in_curr_seq), self.seq_len))\n",
    "                num_peds_considered = 0\n",
    "                _non_linear_ped = []\n",
    "                ped_list = [] #new add\n",
    "                for _, ped_id in enumerate(peds_in_curr_seq):\n",
    "                    curr_ped_seq = curr_seq_data[curr_seq_data[:, 1] == ped_id, :]\n",
    "                    curr_ped_seq = np.around(curr_ped_seq, decimals=4)\n",
    "                    pad_front = frames.index(curr_ped_seq[0, 0]) - idx\n",
    "                    pad_end = frames.index(curr_ped_seq[-1, 0]) - idx + 1\n",
    "                    if pad_end - pad_front != self.seq_len:\n",
    "                        continue\n",
    "                    curr_ped_seq = np.transpose(curr_ped_seq[:, 2:])\n",
    "                    curr_ped_seq = curr_ped_seq\n",
    "                    _idx = num_peds_considered\n",
    "                    curr_seq[_idx, :, pad_front:pad_end] = curr_ped_seq\n",
    "                    # Linear vs Non-Linear Trajectory\n",
    "                    _non_linear_ped.append(poly_fit(curr_ped_seq, pred_len, threshold))\n",
    "                    curr_loss_mask[_idx, pad_front:pad_end] = 1\n",
    "                    num_peds_considered += 1\n",
    "                    ped_list.append(ped_id) #new add\n",
    "\n",
    "                if num_peds_considered > min_ped:\n",
    "                    non_linear_ped += _non_linear_ped\n",
    "                    num_peds_in_seq.append(num_peds_considered)\n",
    "                    loss_mask_list.append(curr_loss_mask[:num_peds_considered])\n",
    "                    seq_list.append(curr_seq[:num_peds_considered])\n",
    "                    frame_id.append(frame_range) #new add\n",
    "                    pedestrain_id.append(ped_list) #new add\n",
    "                    \n",
    "            \n",
    "            # cap = cv2.VideoCapture(self.frame_path + '/seq_hotel.avi')\n",
    "            # frame_lists = [(row.min() , row.max())  for row in frame_id] #new add\n",
    "            # images_list = []\n",
    "            # for tup in frame_lists:\n",
    "            #     temp_list = []\n",
    "            #     current_frame_number = tup[0]\n",
    "            #     for i in range(obs_len):\n",
    "            #         cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame_number)\n",
    "            #         ret, current_frame = cap.read()\n",
    "            #         frame = prepare_image(current_frame).to(device)\n",
    "            #         temp_list.append(frame)\n",
    "            #         current_frame_number+=10\n",
    "            #     images_list.append(temp_list)\n",
    "            # import pickle\n",
    "\n",
    "            # Specify the full path to save the images_list as a pickle file\n",
    "            # save_path = 'D:/AmirKabir/tez/eighen trajectory/project_git/project/project_test_cpu/datasets/image_List_hotel/images_list.pkl'\n",
    "            # with open(save_path, 'wb') as f:\n",
    "            #     pickle.dump(images_list, f)\n",
    "            \n",
    "        # with open(save_path, 'rb') as f:\n",
    "        self.frame_lists = [(row.min(), row.max()) for row in frame_id]\n",
    "        # self.images = extract_frames(video_path, frame_lists, self.obs_len)\n",
    "        self.num_seq = len(seq_list)\n",
    "        seq_list = np.concatenate(seq_list, axis=0)\n",
    "        loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n",
    "        non_linear_ped = np.asarray(non_linear_ped)\n",
    "         #new add\n",
    "        self.pedestrain_id = np.concatenate(pedestrain_id , axis = 0) #new add\n",
    "        self.num_peds_in_seq = np.array(num_peds_in_seq) \n",
    "\n",
    "        # Convert numpy -> Torch Tensor\n",
    "        self.obs_traj = torch.from_numpy(seq_list[:, :, :self.obs_len]).type(torch.float).permute(0, 2, 1)  # NTC\n",
    "        self.pred_traj = torch.from_numpy(seq_list[:, :, self.obs_len:]).type(torch.float).permute(0, 2, 1)  # NTC\n",
    "        self.loss_mask = torch.from_numpy(loss_mask_list).type(torch.float)\n",
    "        self.non_linear_ped = torch.from_numpy(non_linear_ped).type(torch.float)\n",
    "        cum_start_idx = [0] + np.cumsum(num_peds_in_seq).tolist()\n",
    "        self.seq_start_end = [(start, end) for start, end in zip(cum_start_idx, cum_start_idx[1:])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_seq\n",
    "    \n",
    "    def extract_frames(self, video_path, min_frame, max_frame, obs_len):\n",
    "        images_list = []\n",
    "        cap =  cv2.VideoCapture(video_path) \n",
    "        temp_list = []\n",
    "        current_frame_number = min_frame\n",
    "        for _ in range(obs_len):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame_number)\n",
    "            ret, current_frame = cap.read()\n",
    "            if not ret:\n",
    "                raise RuntimeError(f\"Could not read frame {current_frame_number} from {video_path}\")\n",
    "            frame = prepare_image(current_frame).to(device)\n",
    "            temp_list.append(frame)\n",
    "            current_frame_number += 10\n",
    "        images_list.append(temp_list)\n",
    "        return images_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start, end = self.seq_start_end[index]\n",
    "        min_frame, max_frame= self.frame_lists[index]\n",
    "        frames = self.extract_frames(self.video_path, min_frame, max_frame, self.obs_len)\n",
    "        out = [self.obs_traj[start:end], self.pred_traj[start:end],\n",
    "               self.non_linear_ped[start:end], self.loss_mask[start:end], [[0, end - start]], frames]\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'D:/AmirKabir/tez/eighen trajectory/project_git/project/project_test_cpu/datasets/test'\n",
    "loader_train = get_dataloader(dataset_dir, 'train', 8, 12 ,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for data  in loader_train:\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader_train:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            obs_traj, pred_traj = [tensor.to(device, non_blocking=True) for tensor in batch[:2]]\n",
    "            frames = [[tensor.to(device, non_blocking=True) for tensor in sublist] for sublist in batch[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.4980, 0.4118, 0.4588,  ..., 0.5490, 0.5020, 0.5686],\n",
       "           [0.3529, 0.3020, 0.3255,  ..., 0.5608, 0.5020, 0.6078],\n",
       "           [0.2667, 0.2863, 0.4353,  ..., 0.5412, 0.5176, 0.6039],\n",
       "           ...,\n",
       "           [0.2784, 0.2784, 0.2784,  ..., 0.6902, 0.6745, 0.6627],\n",
       "           [0.2627, 0.2627, 0.2627,  ..., 0.6980, 0.6824, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7098, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.5059, 0.4196, 0.4667,  ..., 0.5647, 0.5176, 0.5843],\n",
       "           [0.3608, 0.3098, 0.3333,  ..., 0.5765, 0.5176, 0.6235],\n",
       "           [0.2745, 0.2941, 0.4431,  ..., 0.5569, 0.5333, 0.6196],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6784, 0.6627, 0.6510],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.6980, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.5333, 0.4471, 0.4941,  ..., 0.6000, 0.5529, 0.6196],\n",
       "           [0.3882, 0.3373, 0.3608,  ..., 0.6118, 0.5529, 0.6588],\n",
       "           [0.3020, 0.3216, 0.4706,  ..., 0.5922, 0.5686, 0.6549],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6824, 0.6667, 0.6549],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6902, 0.6824]]]]),\n",
       " tensor([[[[0.5255, 0.4196, 0.4549,  ..., 0.5490, 0.5020, 0.5804],\n",
       "           [0.3765, 0.3098, 0.3176,  ..., 0.5608, 0.5020, 0.6039],\n",
       "           [0.2824, 0.3020, 0.4157,  ..., 0.5412, 0.5216, 0.6000],\n",
       "           ...,\n",
       "           [0.2784, 0.2784, 0.2784,  ..., 0.6902, 0.6745, 0.6627],\n",
       "           [0.2627, 0.2627, 0.2627,  ..., 0.6980, 0.6824, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7098, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.5333, 0.4275, 0.4627,  ..., 0.5647, 0.5176, 0.5961],\n",
       "           [0.3843, 0.3176, 0.3255,  ..., 0.5765, 0.5176, 0.6196],\n",
       "           [0.2902, 0.3098, 0.4235,  ..., 0.5569, 0.5373, 0.6157],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6784, 0.6627, 0.6510],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.6980, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.5608, 0.4549, 0.4902,  ..., 0.6000, 0.5529, 0.6314],\n",
       "           [0.4118, 0.3451, 0.3529,  ..., 0.6118, 0.5529, 0.6549],\n",
       "           [0.3176, 0.3373, 0.4510,  ..., 0.5922, 0.5725, 0.6510],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6824, 0.6667, 0.6549],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6902, 0.6824]]]]),\n",
       " tensor([[[[0.5765, 0.4353, 0.4588,  ..., 0.5529, 0.4980, 0.5804],\n",
       "           [0.3608, 0.2902, 0.3098,  ..., 0.5647, 0.5020, 0.6118],\n",
       "           [0.2980, 0.3255, 0.4235,  ..., 0.5333, 0.5255, 0.6000],\n",
       "           ...,\n",
       "           [0.2784, 0.2784, 0.2784,  ..., 0.6902, 0.6745, 0.6627],\n",
       "           [0.2627, 0.2627, 0.2627,  ..., 0.6980, 0.6824, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7098, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.5843, 0.4431, 0.4667,  ..., 0.5686, 0.5137, 0.5961],\n",
       "           [0.3686, 0.2980, 0.3176,  ..., 0.5804, 0.5176, 0.6275],\n",
       "           [0.3059, 0.3333, 0.4314,  ..., 0.5490, 0.5412, 0.6157],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6784, 0.6627, 0.6510],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.6980, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.6118, 0.4706, 0.4941,  ..., 0.6039, 0.5490, 0.6314],\n",
       "           [0.3961, 0.3255, 0.3451,  ..., 0.6157, 0.5529, 0.6627],\n",
       "           [0.3333, 0.3608, 0.4588,  ..., 0.5843, 0.5765, 0.6510],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6824, 0.6667, 0.6549],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6902, 0.6824]]]]),\n",
       " tensor([[[[0.5529, 0.4510, 0.4784,  ..., 0.5490, 0.5020, 0.5804],\n",
       "           [0.3451, 0.3020, 0.3412,  ..., 0.5529, 0.5098, 0.6078],\n",
       "           [0.3137, 0.3137, 0.3961,  ..., 0.5333, 0.5255, 0.6039],\n",
       "           ...,\n",
       "           [0.2784, 0.2784, 0.2784,  ..., 0.6902, 0.6745, 0.6627],\n",
       "           [0.2627, 0.2627, 0.2627,  ..., 0.6980, 0.6824, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7098, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.5608, 0.4588, 0.4863,  ..., 0.5647, 0.5176, 0.5961],\n",
       "           [0.3529, 0.3098, 0.3490,  ..., 0.5686, 0.5255, 0.6235],\n",
       "           [0.3216, 0.3216, 0.4039,  ..., 0.5490, 0.5412, 0.6196],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6784, 0.6627, 0.6510],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.6980, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.5882, 0.4863, 0.5137,  ..., 0.6000, 0.5529, 0.6314],\n",
       "           [0.3804, 0.3373, 0.3765,  ..., 0.6039, 0.5608, 0.6588],\n",
       "           [0.3490, 0.3490, 0.4314,  ..., 0.5843, 0.5765, 0.6549],\n",
       "           ...,\n",
       "           [0.2980, 0.2980, 0.2980,  ..., 0.6824, 0.6667, 0.6549],\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6902, 0.6824]]]]),\n",
       " tensor([[[[0.5843, 0.4667, 0.4784,  ..., 0.5608, 0.4863, 0.5686],\n",
       "           [0.3451, 0.3176, 0.3176,  ..., 0.5608, 0.4863, 0.6314],\n",
       "           [0.3020, 0.3294, 0.4039,  ..., 0.5255, 0.5294, 0.6157],\n",
       "           ...,\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6667],\n",
       "           [0.2667, 0.2667, 0.2667,  ..., 0.7059, 0.6902, 0.6824],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7137, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.5922, 0.4745, 0.4863,  ..., 0.5765, 0.5020, 0.5843],\n",
       "           [0.3529, 0.3255, 0.3255,  ..., 0.5765, 0.5020, 0.6471],\n",
       "           [0.3098, 0.3373, 0.4118,  ..., 0.5412, 0.5451, 0.6314],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6784, 0.6627, 0.6549],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6941, 0.6784, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.6196, 0.5020, 0.5137,  ..., 0.6118, 0.5373, 0.6196],\n",
       "           [0.3804, 0.3529, 0.3529,  ..., 0.6118, 0.5373, 0.6824],\n",
       "           [0.3373, 0.3647, 0.4392,  ..., 0.5765, 0.5804, 0.6667],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6824, 0.6667, 0.6588],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6980, 0.6824, 0.6745],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7059, 0.6902, 0.6824]]]]),\n",
       " tensor([[[[0.5569, 0.4275, 0.4627,  ..., 0.5608, 0.4863, 0.5725],\n",
       "           [0.3647, 0.3216, 0.3294,  ..., 0.5608, 0.4902, 0.6235],\n",
       "           [0.2824, 0.3255, 0.3922,  ..., 0.5255, 0.5294, 0.6118],\n",
       "           ...,\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6627],\n",
       "           [0.2667, 0.2667, 0.2667,  ..., 0.7020, 0.6863, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7137, 0.6980, 0.6863]],\n",
       " \n",
       "          [[0.5647, 0.4353, 0.4706,  ..., 0.5765, 0.5020, 0.5882],\n",
       "           [0.3725, 0.3294, 0.3373,  ..., 0.5765, 0.5059, 0.6392],\n",
       "           [0.2902, 0.3333, 0.4000,  ..., 0.5412, 0.5451, 0.6275],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6745, 0.6588, 0.6510],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6902, 0.6745, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6863, 0.6745]],\n",
       " \n",
       "          [[0.5922, 0.4627, 0.4980,  ..., 0.6118, 0.5373, 0.6235],\n",
       "           [0.4000, 0.3569, 0.3647,  ..., 0.6118, 0.5412, 0.6745],\n",
       "           [0.3176, 0.3608, 0.4275,  ..., 0.5765, 0.5804, 0.6627],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6784, 0.6627, 0.6549],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6941, 0.6784, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7059, 0.6902, 0.6784]]]]),\n",
       " tensor([[[[0.4824, 0.4157, 0.4706,  ..., 0.5608, 0.4902, 0.5647],\n",
       "           [0.3216, 0.3059, 0.3255,  ..., 0.5647, 0.4824, 0.6118],\n",
       "           [0.2784, 0.2980, 0.3686,  ..., 0.5451, 0.5098, 0.6196],\n",
       "           ...,\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6863, 0.6706, 0.6627],\n",
       "           [0.2667, 0.2667, 0.2667,  ..., 0.7020, 0.6863, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7137, 0.6980, 0.6863]],\n",
       " \n",
       "          [[0.4902, 0.4235, 0.4784,  ..., 0.5765, 0.5059, 0.5804],\n",
       "           [0.3294, 0.3137, 0.3333,  ..., 0.5804, 0.4980, 0.6275],\n",
       "           [0.2863, 0.3059, 0.3765,  ..., 0.5608, 0.5255, 0.6353],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6745, 0.6588, 0.6510],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6902, 0.6745, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6863, 0.6745]],\n",
       " \n",
       "          [[0.5176, 0.4510, 0.5059,  ..., 0.6118, 0.5412, 0.6157],\n",
       "           [0.3569, 0.3412, 0.3608,  ..., 0.6157, 0.5333, 0.6627],\n",
       "           [0.3137, 0.3333, 0.4039,  ..., 0.5961, 0.5608, 0.6706],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6784, 0.6627, 0.6549],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6941, 0.6784, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7059, 0.6902, 0.6784]]]]),\n",
       " tensor([[[[0.4627, 0.4000, 0.4549,  ..., 0.5608, 0.4863, 0.5608],\n",
       "           [0.3020, 0.2824, 0.3137,  ..., 0.5647, 0.4863, 0.6118],\n",
       "           [0.2588, 0.2784, 0.3490,  ..., 0.5451, 0.5098, 0.6235],\n",
       "           ...,\n",
       "           [0.2824, 0.2824, 0.2824,  ..., 0.6902, 0.6745, 0.6667],\n",
       "           [0.2667, 0.2667, 0.2667,  ..., 0.7020, 0.6863, 0.6784],\n",
       "           [0.2549, 0.2549, 0.2549,  ..., 0.7137, 0.6980, 0.6902]],\n",
       " \n",
       "          [[0.4706, 0.4078, 0.4627,  ..., 0.5765, 0.5020, 0.5765],\n",
       "           [0.3098, 0.2902, 0.3216,  ..., 0.5804, 0.5020, 0.6275],\n",
       "           [0.2667, 0.2863, 0.3569,  ..., 0.5608, 0.5255, 0.6392],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6784, 0.6627, 0.6549],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6902, 0.6745, 0.6667],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7020, 0.6863, 0.6784]],\n",
       " \n",
       "          [[0.4980, 0.4353, 0.4902,  ..., 0.6118, 0.5373, 0.6118],\n",
       "           [0.3373, 0.3176, 0.3490,  ..., 0.6157, 0.5373, 0.6627],\n",
       "           [0.2941, 0.3137, 0.3843,  ..., 0.5961, 0.5608, 0.6745],\n",
       "           ...,\n",
       "           [0.3020, 0.3020, 0.3020,  ..., 0.6824, 0.6667, 0.6588],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.6941, 0.6784, 0.6706],\n",
       "           [0.2745, 0.2745, 0.2745,  ..., 0.7059, 0.6902, 0.6824]]]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(_path, delim='\\t'):\n",
    "    data = []\n",
    "    if delim == 'tab':\n",
    "        delim = '\\t'\n",
    "    elif delim == 'space':\n",
    "        delim = ' '\n",
    "    with open(_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(delim)\n",
    "            line = [float(i) for i in line]\n",
    "            data.append(line)\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fit(traj, traj_len, threshold):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - traj: Numpy array of shape (2, traj_len)\n",
    "    - traj_len: Len of trajectory\n",
    "    - threshold: Minimum error to be considered for non-linear traj\n",
    "    Output:\n",
    "    - int: 1 -> Non Linear 0-> Linear\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, traj_len - 1, traj_len)\n",
    "    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1]\n",
    "    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1]\n",
    "    if res_x + res_y >= threshold:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_peds_in_seq = []\n",
    "seq_list = []\n",
    "loss_mask_list = []\n",
    "non_linear_ped = []\n",
    "frame_id = []\n",
    "path = 'D:/AmirKabir/tez/eighen trajectory/nuscenes_test_cpu/nuscenes_test_cpu/datasets/eth/train/biwi_hotel_train.txt'\n",
    "try:\n",
    "    data = read_file(path)\n",
    "except:\n",
    "    data = read_file(path, delim = 'space')\n",
    "        \n",
    "frames = np.unique(data[:, 0]).tolist()\n",
    "frame_data = []\n",
    "for frame in frames:\n",
    "    frame_data.append(data[frame == data[:, 0], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "obs_len = 8\n",
    "skip = 1\n",
    "pred_len = 12\n",
    "threshold=0.02\n",
    "min_ped=1\n",
    "num_sequences = int(math.ceil((len(frames) - seq_len + 1) / skip))\n",
    "num_peds_in_seq = []\n",
    "seq_list = []\n",
    "loss_mask_list = []\n",
    "non_linear_ped = []\n",
    "frame_id = []\n",
    "pedestrain_id = []\n",
    "for idx in range(0, num_sequences * skip + 1, skip):\n",
    "    curr_seq_data = np.concatenate(frame_data[idx:idx + seq_len], axis=0)\n",
    "    peds_in_curr_seq = np.unique(curr_seq_data[:, 1])\n",
    "    frame_range = np.unique(curr_seq_data[:, 0])\n",
    "    curr_seq = np.zeros((len(peds_in_curr_seq), 2, seq_len))\n",
    "    curr_loss_mask = np.zeros((len(peds_in_curr_seq), seq_len))\n",
    "    num_peds_considered = 0\n",
    "    _non_linear_ped = []\n",
    "    ped_list = []\n",
    "    for _, ped_id in enumerate(peds_in_curr_seq):\n",
    "        curr_ped_seq = curr_seq_data[curr_seq_data[:, 1] == ped_id, :]\n",
    "        curr_ped_seq = np.around(curr_ped_seq, decimals=4)\n",
    "        pad_front = frames.index(curr_ped_seq[0, 0]) - idx\n",
    "        pad_end = frames.index(curr_ped_seq[-1, 0]) - idx + 1\n",
    "        if pad_end - pad_front != seq_len:\n",
    "            continue\n",
    "        curr_ped_seq = np.transpose(curr_ped_seq[:, 2:])\n",
    "        curr_ped_seq = curr_ped_seq\n",
    "        _idx = num_peds_considered\n",
    "        curr_seq[_idx, :, pad_front:pad_end] = curr_ped_seq\n",
    "        # Linear vs Non-Linear Trajectory\n",
    "        _non_linear_ped.append(poly_fit(curr_ped_seq, pred_len, threshold))\n",
    "        curr_loss_mask[_idx, pad_front:pad_end] = 1\n",
    "        num_peds_considered += 1\n",
    "        ped_list.append(ped_id)\n",
    "\n",
    "\n",
    "    if num_peds_considered > min_ped:\n",
    "        non_linear_ped += _non_linear_ped\n",
    "        num_peds_in_seq.append(num_peds_considered)\n",
    "        loss_mask_list.append(curr_loss_mask[:num_peds_considered])\n",
    "        seq_list.append(curr_seq[:num_peds_considered])\n",
    "        frame_id.append(frame_range)\n",
    "        pedestrain_id.append(ped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = len(seq_list)\n",
    "seq_list = np.concatenate(seq_list, axis=0)\n",
    "loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n",
    "frame_lists = [(row.min() , row.max())  for row in frame_id]\n",
    "non_linear_ped = np.asarray(non_linear_ped)\n",
    "num_peds_in_seq = np.array(num_peds_in_seq)\n",
    "pedestrain_id = np.concatenate(pedestrain_id , axis = 0)\n",
    "# Convert numpy -> Torch T\n",
    "obs_traj = torch.from_numpy(seq_list[:, :, :obs_len]).type(torch.float).permute(0, 2, 1)  # NTC\n",
    "pred_traj = torch.from_numpy(seq_list[:, :, obs_len:]).type(torch.float).permute(0, 2, 1)  # NTC\n",
    "loss_mask = torch.from_numpy(loss_mask_list).type(torch.float)\n",
    "non_linear_ped = torch.from_numpy(non_linear_ped).type(torch.float)\n",
    "cum_start_idx = [0] + np.cumsum(num_peds_in_seq).tolist()\n",
    "seq_start_end = [(start, end) for start, end in zip(cum_start_idx, cum_start_idx[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5,\n",
       "       5, 5, 5, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 2, 2, 2, 3, 2, 2, 2, 5, 5, 5, 3, 3,\n",
       "       5, 5, 5, 4, 5, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3,\n",
       "       2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2,\n",
       "       2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 6, 6, 6, 6, 8, 7, 5, 5, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_peds_in_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_traj_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 190.0),\n",
       " (10.0, 200.0),\n",
       " (20.0, 210.0),\n",
       " (30.0, 220.0),\n",
       " (40.0, 230.0),\n",
       " (50.0, 240.0),\n",
       " (60.0, 250.0),\n",
       " (500.0, 690.0),\n",
       " (510.0, 700.0),\n",
       " (520.0, 710.0),\n",
       " (530.0, 720.0),\n",
       " (540.0, 730.0),\n",
       " (550.0, 740.0),\n",
       " (560.0, 750.0),\n",
       " (570.0, 760.0),\n",
       " (580.0, 770.0),\n",
       " (590.0, 780.0),\n",
       " (600.0, 790.0),\n",
       " (610.0, 800.0),\n",
       " (1150.0, 1340.0),\n",
       " (1160.0, 1350.0),\n",
       " (1170.0, 1360.0),\n",
       " (1180.0, 1370.0),\n",
       " (1190.0, 1380.0),\n",
       " (2770.0, 2960.0),\n",
       " (2780.0, 2970.0),\n",
       " (2790.0, 2980.0),\n",
       " (4000.0, 4190.0),\n",
       " (4010.0, 4200.0),\n",
       " (4020.0, 4210.0),\n",
       " (4030.0, 4220.0),\n",
       " (4040.0, 4230.0),\n",
       " (4050.0, 4240.0),\n",
       " (4060.0, 4250.0),\n",
       " (4070.0, 4260.0),\n",
       " (4430.0, 4620.0),\n",
       " (4440.0, 4630.0),\n",
       " (4450.0, 4640.0),\n",
       " (4460.0, 4650.0),\n",
       " (4470.0, 4660.0),\n",
       " (4480.0, 4670.0),\n",
       " (4490.0, 4680.0),\n",
       " (4500.0, 4690.0),\n",
       " (4510.0, 4700.0),\n",
       " (4520.0, 4710.0),\n",
       " (4530.0, 4720.0),\n",
       " (4540.0, 4730.0),\n",
       " (4550.0, 4740.0),\n",
       " (4560.0, 4750.0),\n",
       " (4570.0, 4760.0),\n",
       " (4580.0, 4770.0),\n",
       " (4590.0, 4780.0),\n",
       " (4600.0, 4790.0),\n",
       " (4610.0, 4800.0),\n",
       " (4620.0, 4810.0),\n",
       " (4630.0, 4820.0),\n",
       " (4640.0, 4830.0),\n",
       " (4650.0, 4840.0),\n",
       " (4660.0, 4850.0),\n",
       " (4670.0, 4860.0),\n",
       " (4680.0, 4870.0),\n",
       " (4690.0, 4880.0),\n",
       " (4700.0, 4890.0),\n",
       " (4710.0, 4900.0),\n",
       " (4720.0, 4910.0),\n",
       " (4730.0, 4920.0),\n",
       " (4740.0, 4930.0),\n",
       " (4750.0, 4940.0),\n",
       " (4760.0, 4950.0),\n",
       " (4770.0, 4960.0),\n",
       " (4780.0, 4970.0),\n",
       " (4790.0, 4980.0),\n",
       " (4800.0, 4990.0),\n",
       " (4810.0, 5000.0),\n",
       " (4820.0, 5010.0),\n",
       " (5680.0, 5870.0),\n",
       " (5690.0, 5880.0),\n",
       " (5700.0, 5890.0),\n",
       " (5710.0, 5900.0),\n",
       " (6840.0, 7030.0),\n",
       " (6850.0, 7040.0),\n",
       " (6860.0, 7050.0),\n",
       " (6870.0, 7060.0),\n",
       " (6880.0, 7070.0),\n",
       " (6890.0, 7080.0),\n",
       " (6900.0, 7090.0),\n",
       " (6910.0, 7100.0),\n",
       " (6920.0, 7110.0),\n",
       " (6930.0, 7120.0),\n",
       " (6940.0, 7130.0),\n",
       " (6950.0, 7140.0),\n",
       " (6960.0, 7150.0),\n",
       " (6970.0, 7160.0),\n",
       " (6980.0, 7170.0),\n",
       " (6990.0, 7180.0),\n",
       " (7000.0, 7190.0),\n",
       " (7010.0, 7200.0),\n",
       " (7020.0, 7210.0),\n",
       " (7030.0, 7220.0),\n",
       " (7040.0, 7230.0),\n",
       " (7050.0, 7240.0),\n",
       " (7060.0, 7250.0),\n",
       " (7070.0, 7260.0),\n",
       " (7080.0, 7270.0),\n",
       " (7090.0, 7280.0),\n",
       " (7100.0, 7290.0),\n",
       " (7110.0, 7300.0),\n",
       " (7120.0, 7310.0),\n",
       " (7130.0, 7320.0),\n",
       " (7140.0, 7330.0),\n",
       " (7150.0, 7340.0),\n",
       " (7160.0, 7350.0),\n",
       " (7170.0, 7360.0),\n",
       " (7180.0, 7370.0),\n",
       " (7480.0, 7670.0),\n",
       " (9260.0, 9450.0),\n",
       " (9270.0, 9460.0),\n",
       " (9400.0, 9590.0),\n",
       " (9410.0, 9600.0),\n",
       " (9420.0, 9610.0),\n",
       " (9430.0, 9620.0),\n",
       " (9440.0, 9630.0),\n",
       " (9450.0, 9640.0),\n",
       " (9460.0, 9650.0),\n",
       " (9470.0, 9660.0),\n",
       " (9480.0, 9670.0),\n",
       " (9490.0, 9680.0),\n",
       " (9500.0, 9690.0),\n",
       " (9510.0, 9700.0),\n",
       " (9520.0, 9710.0),\n",
       " (9530.0, 9720.0),\n",
       " (9540.0, 9730.0),\n",
       " (9550.0, 9740.0),\n",
       " (9560.0, 9750.0),\n",
       " (9570.0, 9760.0),\n",
       " (9580.0, 9770.0),\n",
       " (9590.0, 9780.0),\n",
       " (9600.0, 9790.0),\n",
       " (9610.0, 9800.0),\n",
       " (9620.0, 9810.0),\n",
       " (9630.0, 9820.0),\n",
       " (9640.0, 9830.0),\n",
       " (9650.0, 9840.0),\n",
       " (9660.0, 9850.0),\n",
       " (9670.0, 9860.0),\n",
       " (9680.0, 9870.0),\n",
       " (9690.0, 9880.0),\n",
       " (9700.0, 9890.0),\n",
       " (9710.0, 9900.0),\n",
       " (9720.0, 9910.0),\n",
       " (9730.0, 9920.0),\n",
       " (9740.0, 9930.0),\n",
       " (9750.0, 9940.0),\n",
       " (9760.0, 9950.0),\n",
       " (9770.0, 9960.0),\n",
       " (9780.0, 9970.0),\n",
       " (9790.0, 9980.0),\n",
       " (9800.0, 9990.0),\n",
       " (10060.0, 10250.0),\n",
       " (10070.0, 10260.0),\n",
       " (10080.0, 10270.0),\n",
       " (10090.0, 10280.0),\n",
       " (10100.0, 10290.0),\n",
       " (10110.0, 10300.0),\n",
       " (10120.0, 10310.0),\n",
       " (10130.0, 10320.0),\n",
       " (10140.0, 10330.0),\n",
       " (10150.0, 10340.0),\n",
       " (10260.0, 10450.0),\n",
       " (10270.0, 10460.0),\n",
       " (10280.0, 10470.0),\n",
       " (10290.0, 10480.0),\n",
       " (10300.0, 10490.0),\n",
       " (10310.0, 10500.0),\n",
       " (10320.0, 10510.0),\n",
       " (10330.0, 10520.0),\n",
       " (10340.0, 10530.0),\n",
       " (10350.0, 10540.0),\n",
       " (10360.0, 10550.0),\n",
       " (10370.0, 10560.0),\n",
       " (10380.0, 10570.0),\n",
       " (10390.0, 10580.0),\n",
       " (10400.0, 10590.0),\n",
       " (10410.0, 10600.0),\n",
       " (10420.0, 10610.0),\n",
       " (10430.0, 10620.0),\n",
       " (10440.0, 10630.0),\n",
       " (10450.0, 10640.0),\n",
       " (10460.0, 10650.0),\n",
       " (10470.0, 10660.0),\n",
       " (10480.0, 10670.0),\n",
       " (10490.0, 10680.0),\n",
       " (10500.0, 10690.0),\n",
       " (10510.0, 10700.0),\n",
       " (10520.0, 10710.0),\n",
       " (10530.0, 10720.0),\n",
       " (10540.0, 10730.0),\n",
       " (11010.0, 11200.0),\n",
       " (11020.0, 11210.0),\n",
       " (11350.0, 11540.0),\n",
       " (11770.0, 11960.0),\n",
       " (12480.0, 12670.0),\n",
       " (12520.0, 12710.0),\n",
       " (12530.0, 12720.0),\n",
       " (12540.0, 12730.0),\n",
       " (12550.0, 12740.0),\n",
       " (12560.0, 12750.0),\n",
       " (12700.0, 12890.0),\n",
       " (12980.0, 13170.0),\n",
       " (12990.0, 13180.0),\n",
       " (13000.0, 13190.0),\n",
       " (13010.0, 13200.0),\n",
       " (13020.0, 13210.0),\n",
       " (13030.0, 13220.0),\n",
       " (13040.0, 13230.0),\n",
       " (13060.0, 13250.0),\n",
       " (13070.0, 13260.0),\n",
       " (13080.0, 13270.0),\n",
       " (13090.0, 13280.0),\n",
       " (13100.0, 13290.0),\n",
       " (13110.0, 13300.0),\n",
       " (13120.0, 13310.0),\n",
       " (13130.0, 13320.0),\n",
       " (13140.0, 13330.0),\n",
       " (13150.0, 13340.0),\n",
       " (13160.0, 13350.0),\n",
       " (13170.0, 13360.0),\n",
       " (13180.0, 13370.0),\n",
       " (13190.0, 13380.0),\n",
       " (13200.0, 13390.0),\n",
       " (13210.0, 13400.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 190),\n",
       " (10, 200),\n",
       " (20, 210),\n",
       " (30, 220),\n",
       " (40, 230),\n",
       " (50, 240),\n",
       " (60, 250),\n",
       " (500, 690),\n",
       " (510, 700),\n",
       " (520, 710),\n",
       " (530, 720),\n",
       " (540, 730),\n",
       " (550, 740),\n",
       " (560, 750),\n",
       " (570, 760),\n",
       " (580, 770),\n",
       " (590, 780),\n",
       " (600, 790),\n",
       " (610, 800),\n",
       " (1150, 1340),\n",
       " (1160, 1350),\n",
       " (1170, 1360),\n",
       " (1180, 1370),\n",
       " (1190, 1380),\n",
       " (2770, 2960),\n",
       " (2780, 2970),\n",
       " (2790, 2980),\n",
       " (4000, 4190),\n",
       " (4010, 4200),\n",
       " (4020, 4210),\n",
       " (4030, 4220),\n",
       " (4040, 4230),\n",
       " (4050, 4240),\n",
       " (4060, 4250),\n",
       " (4070, 4260),\n",
       " (4430, 4620),\n",
       " (4440, 4630),\n",
       " (4450, 4640),\n",
       " (4460, 4650),\n",
       " (4470, 4660),\n",
       " (4480, 4670),\n",
       " (4490, 4680),\n",
       " (4500, 4690),\n",
       " (4510, 4700),\n",
       " (4520, 4710),\n",
       " (4530, 4720),\n",
       " (4540, 4730),\n",
       " (4550, 4740),\n",
       " (4560, 4750),\n",
       " (4570, 4760),\n",
       " (4580, 4770),\n",
       " (4590, 4780),\n",
       " (4600, 4790),\n",
       " (4610, 4800),\n",
       " (4620, 4810),\n",
       " (4630, 4820),\n",
       " (4640, 4830),\n",
       " (4650, 4840),\n",
       " (4660, 4850),\n",
       " (4670, 4860),\n",
       " (4680, 4870),\n",
       " (4690, 4880),\n",
       " (4700, 4890),\n",
       " (4710, 4900),\n",
       " (4720, 4910),\n",
       " (4730, 4920),\n",
       " (4740, 4930),\n",
       " (4750, 4940),\n",
       " (4760, 4950),\n",
       " (4770, 4960),\n",
       " (4780, 4970),\n",
       " (4790, 4980),\n",
       " (4800, 4990),\n",
       " (4810, 5000),\n",
       " (4820, 5010),\n",
       " (5680, 5870),\n",
       " (5690, 5880),\n",
       " (5700, 5890),\n",
       " (5710, 5900),\n",
       " (6840, 7030),\n",
       " (6850, 7040),\n",
       " (6860, 7050),\n",
       " (6870, 7060),\n",
       " (6880, 7070),\n",
       " (6890, 7080),\n",
       " (6900, 7090),\n",
       " (6910, 7100),\n",
       " (6920, 7110),\n",
       " (6930, 7120),\n",
       " (6940, 7130),\n",
       " (6950, 7140),\n",
       " (6960, 7150),\n",
       " (6970, 7160),\n",
       " (6980, 7170),\n",
       " (6990, 7180),\n",
       " (7000, 7190),\n",
       " (7010, 7200),\n",
       " (7020, 7210),\n",
       " (7030, 7220),\n",
       " (7040, 7230),\n",
       " (7050, 7240),\n",
       " (7060, 7250),\n",
       " (7070, 7260),\n",
       " (7080, 7270),\n",
       " (7090, 7280),\n",
       " (7100, 7290),\n",
       " (7110, 7300),\n",
       " (7120, 7310),\n",
       " (7130, 7320),\n",
       " (7140, 7330),\n",
       " (7150, 7340),\n",
       " (7160, 7350),\n",
       " (7170, 7360),\n",
       " (7180, 7370),\n",
       " (7480, 7670),\n",
       " (9260, 9450),\n",
       " (9270, 9460),\n",
       " (9400, 9590),\n",
       " (9410, 9600),\n",
       " (9420, 9610),\n",
       " (9430, 9620),\n",
       " (9440, 9630),\n",
       " (9450, 9640),\n",
       " (9460, 9650),\n",
       " (9470, 9660),\n",
       " (9480, 9670),\n",
       " (9490, 9680),\n",
       " (9500, 9690),\n",
       " (9510, 9700),\n",
       " (9520, 9710),\n",
       " (9530, 9720),\n",
       " (9540, 9730),\n",
       " (9550, 9740),\n",
       " (9560, 9750),\n",
       " (9570, 9760),\n",
       " (9580, 9770),\n",
       " (9590, 9780),\n",
       " (9600, 9790),\n",
       " (9610, 9800),\n",
       " (9620, 9810),\n",
       " (9630, 9820),\n",
       " (9640, 9830),\n",
       " (9650, 9840),\n",
       " (9660, 9850),\n",
       " (9670, 9860),\n",
       " (9680, 9870),\n",
       " (9690, 9880),\n",
       " (9700, 9890),\n",
       " (9710, 9900),\n",
       " (9720, 9910),\n",
       " (9730, 9920),\n",
       " (9740, 9930),\n",
       " (9750, 9940),\n",
       " (9760, 9950),\n",
       " (9770, 9960),\n",
       " (9780, 9970),\n",
       " (9790, 9980),\n",
       " (9800, 9990),\n",
       " (10060, 10250),\n",
       " (10070, 10260),\n",
       " (10080, 10270),\n",
       " (10090, 10280),\n",
       " (10100, 10290),\n",
       " (10110, 10300),\n",
       " (10120, 10310),\n",
       " (10130, 10320),\n",
       " (10140, 10330),\n",
       " (10150, 10340),\n",
       " (10260, 10450),\n",
       " (10270, 10460),\n",
       " (10280, 10470),\n",
       " (10290, 10480),\n",
       " (10300, 10490),\n",
       " (10310, 10500),\n",
       " (10320, 10510),\n",
       " (10330, 10520),\n",
       " (10340, 10530),\n",
       " (10350, 10540),\n",
       " (10360, 10550),\n",
       " (10370, 10560),\n",
       " (10380, 10570),\n",
       " (10390, 10580),\n",
       " (10400, 10590),\n",
       " (10410, 10600),\n",
       " (10420, 10610),\n",
       " (10430, 10620),\n",
       " (10440, 10630),\n",
       " (10450, 10640),\n",
       " (10460, 10650),\n",
       " (10470, 10660),\n",
       " (10480, 10670),\n",
       " (10490, 10680),\n",
       " (10500, 10690),\n",
       " (10510, 10700),\n",
       " (10520, 10710),\n",
       " (10530, 10720),\n",
       " (10540, 10730),\n",
       " (11010, 11200),\n",
       " (11020, 11210),\n",
       " (11350, 11540),\n",
       " (11770, 11960),\n",
       " (12480, 12670),\n",
       " (12520, 12710),\n",
       " (12530, 12720),\n",
       " (12540, 12730),\n",
       " (12550, 12740),\n",
       " (12560, 12750),\n",
       " (12700, 12890),\n",
       " (12980, 13170),\n",
       " (12990, 13180),\n",
       " (13000, 13190),\n",
       " (13010, 13200),\n",
       " (13020, 13210),\n",
       " (13030, 13220),\n",
       " (13040, 13230),\n",
       " (13060, 13250),\n",
       " (13070, 13260),\n",
       " (13080, 13270),\n",
       " (13090, 13280),\n",
       " (13100, 13290),\n",
       " (13110, 13300),\n",
       " (13120, 13310),\n",
       " (13130, 13320),\n",
       " (13140, 13330),\n",
       " (13150, 13340),\n",
       " (13160, 13350),\n",
       " (13170, 13360),\n",
       " (13180, 13370),\n",
       " (13190, 13380),\n",
       " (13200, 13390),\n",
       " (13210, 13400)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72, -1.72,\n",
       "        -1.72, -1.72, -1.7 , -1.7 , -1.7 , -1.7 , -1.7 , -1.7 , -1.7 ,\n",
       "        -1.7 , -1.7 ],\n",
       "       [ 1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,\n",
       "         1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,  1.32,\n",
       "         1.32,  1.32]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in loader_train:\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.0368,  9.7595],\n",
       "         [ 8.5590,  9.5941],\n",
       "         [ 9.0889,  9.4349],\n",
       "         [ 9.6191,  9.2653],\n",
       "         [10.1490,  9.0531],\n",
       "         [10.6792,  8.8409],\n",
       "         [11.2456,  8.6915],\n",
       "         [11.8481,  8.6049],\n",
       "         [12.4444,  8.4753],\n",
       "         [13.0253,  8.2462],\n",
       "         [13.6061,  8.0171],\n",
       "         [14.1433,  7.8023]],\n",
       "\n",
       "        [[ 8.0023,  9.1593],\n",
       "         [ 8.4544,  8.9648],\n",
       "         [ 8.9692,  8.7426],\n",
       "         [ 9.4996,  8.5135],\n",
       "         [10.0386,  8.2913],\n",
       "         [10.5973,  8.0856],\n",
       "         [11.1561,  7.8798],\n",
       "         [11.7370,  7.6770],\n",
       "         [12.3507,  7.4779],\n",
       "         [12.9647,  7.2791],\n",
       "         [13.5407,  7.1094],\n",
       "         [14.1167,  6.9400]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
