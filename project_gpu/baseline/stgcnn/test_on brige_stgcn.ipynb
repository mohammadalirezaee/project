{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvTemporalGraphical(nn.Module):\n",
    "    r\"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int): Size of the graph convolving kernel\n",
    "        t_kernel_size (int): Size of the temporal convolving kernel\n",
    "        t_stride (int, optional): Stride of the temporal convolution. Default: 1\n",
    "        t_padding (int, optional): Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        t_dilation (int, optional): Spacing between temporal kernel elements.\n",
    "            Default: 1\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the output.\n",
    "            Default: ``True``\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Outpu graph sequence in :math:`(N, out_channels, T_{out}, V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, t_kernel_size=1, t_stride=1, t_padding=0, t_dilation=1, bias=True):\n",
    "        super(ConvTemporalGraphical, self).__init__()\n",
    "        self.kernel_size = kernel_size # seq length\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * kernel_size, kernel_size=(t_kernel_size, 1), padding=(t_padding, 0), stride=(t_stride, 1), dilation=(t_dilation, 1), bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        assert A.size(0) == self.kernel_size\n",
    "\n",
    "        x = self.conv(x) #  torch.Size([1, 160, 8, 3])\n",
    "        n, kc, t, v = x.size()\n",
    "        # Print the values\n",
    "        # print(\"x :first \", x.shape)\n",
    "        x = x.view(n, self.kernel_size, kc // self.kernel_size, t, v) # torch.Size([1, 8, 20, 8, 3])\n",
    "        # print(\"x :view \", x.shape)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A)) # torch.Size([1, 20, 8, 3])\n",
    "        # print(\"x :einsum \", x.shape)\n",
    "        return x.contiguous(), A\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
