{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "obs_data = torch.rand(8, 3)  # Random tensor of shape [136, 3]\n",
    "v = obs_data[None, :, :, None].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = v.permute(0, 3, 1, 2)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0142, 0.1671, 0.6769],\n",
       "        [0.1526, 0.3822, 0.9765],\n",
       "        [0.0939, 0.7863, 0.6377],\n",
       "        [0.8530, 0.9523, 0.9712],\n",
       "        [0.4906, 0.8465, 0.0606],\n",
       "        [0.9110, 0.3630, 0.5717],\n",
       "        [0.7558, 0.1802, 0.0386],\n",
       "        [0.8728, 0.2853, 0.2821]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0142, 0.1671, 0.6769],\n",
       "        [0.1526, 0.3822, 0.9765],\n",
       "        [0.0939, 0.7863, 0.6377],\n",
       "        [0.8530, 0.9523, 0.9712],\n",
       "        [0.4906, 0.8465, 0.0606],\n",
       "        [0.9110, 0.3630, 0.5717],\n",
       "        [0.7558, 0.1802, 0.0386],\n",
       "        [0.8728, 0.2853, 0.2821]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 1, 8]),\n",
       " tensor([[[[0.0142, 0.1526, 0.0939, 0.8530, 0.4906, 0.9110, 0.7558, 0.8728]],\n",
       " \n",
       "          [[0.1671, 0.3822, 0.7863, 0.9523, 0.8465, 0.3630, 0.1802, 0.2853]],\n",
       " \n",
       "          [[0.6769, 0.9765, 0.6377, 0.9712, 0.0606, 0.5717, 0.0386, 0.2821]]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = v.permute(0, 3, 1, 2)\n",
    "v.shape , v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ped = v.size(-1)\n",
    "n_ped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769],\n",
       "           [0.0142, 0.1671, 0.6769]],\n",
       "\n",
       "          [[0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765],\n",
       "           [0.1526, 0.3822, 0.9765]],\n",
       "\n",
       "          [[0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377],\n",
       "           [0.0939, 0.7863, 0.6377]],\n",
       "\n",
       "          [[0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712],\n",
       "           [0.8530, 0.9523, 0.9712]],\n",
       "\n",
       "          [[0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606],\n",
       "           [0.4906, 0.8465, 0.0606]],\n",
       "\n",
       "          [[0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717],\n",
       "           [0.9110, 0.3630, 0.5717]],\n",
       "\n",
       "          [[0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386],\n",
       "           [0.7558, 0.1802, 0.0386]],\n",
       "\n",
       "          [[0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821],\n",
       "           [0.8728, 0.2853, 0.2821]]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = v.permute(0, 2, 3, 1).unsqueeze(dim=-2).repeat_interleave(repeats=n_ped, dim=-2)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 8, 3]),\n",
       " tensor([[[[[0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769],\n",
       "            [0.0142, 0.1671, 0.6769]],\n",
       " \n",
       "           [[0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765],\n",
       "            [0.1526, 0.3822, 0.9765]],\n",
       " \n",
       "           [[0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377],\n",
       "            [0.0939, 0.7863, 0.6377]],\n",
       " \n",
       "           [[0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712],\n",
       "            [0.8530, 0.9523, 0.9712]],\n",
       " \n",
       "           [[0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606],\n",
       "            [0.4906, 0.8465, 0.0606]],\n",
       " \n",
       "           [[0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717],\n",
       "            [0.9110, 0.3630, 0.5717]],\n",
       " \n",
       "           [[0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386],\n",
       "            [0.7558, 0.1802, 0.0386]],\n",
       " \n",
       "           [[0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821],\n",
       "            [0.8728, 0.2853, 0.2821]]]]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape  ,temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (temp - temp.transpose(2, 3)).norm(p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.3939, 0.6255, 1.1860, 1.0337, 0.9240, 0.9785, 0.9524],\n",
       "          [0.3939, 0.0000, 0.5306, 0.9031, 1.0811, 0.8599, 1.1333, 1.0051],\n",
       "          [0.6255, 0.5306, 0.0000, 0.8456, 0.7030, 0.9227, 1.0791, 0.9921],\n",
       "          [1.1860, 0.9031, 0.8456, 0.0000, 0.9858, 0.7143, 1.2146, 0.9591],\n",
       "          [1.0337, 1.0811, 0.7030, 0.9858, 0.0000, 0.8196, 0.7175, 0.7142],\n",
       "          [0.9240, 0.8599, 0.9227, 0.7143, 0.8196, 0.0000, 0.5846, 0.3022],\n",
       "          [0.9785, 1.1333, 1.0791, 1.2146, 0.7175, 0.5846, 0.0000, 0.2899],\n",
       "          [0.9524, 1.0051, 0.9921, 0.9591, 0.7142, 0.3022, 0.2899, 0.0000]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_inv = 1. / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_inv[a == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 2.5384, 1.5986, 0.8432, 0.9674, 1.0822, 1.0219, 1.0500],\n",
       "          [2.5384, 0.0000, 1.8847, 1.1073, 0.9250, 1.1629, 0.8824, 0.9949],\n",
       "          [1.5986, 1.8847, 0.0000, 1.1826, 1.4225, 1.0838, 0.9267, 1.0080],\n",
       "          [0.8432, 1.1073, 1.1826, 0.0000, 1.0144, 1.4000, 0.8233, 1.0426],\n",
       "          [0.9674, 0.9250, 1.4225, 1.0144, 0.0000, 1.2201, 1.3938, 1.4002],\n",
       "          [1.0822, 1.1629, 1.0838, 1.4000, 1.2201, 0.0000, 1.7106, 3.3087],\n",
       "          [1.0219, 0.8824, 0.9267, 0.8233, 1.3938, 1.7106, 0.0000, 3.4489],\n",
       "          [1.0500, 0.9949, 1.0080, 1.0426, 1.4002, 3.3087, 3.4489, 0.0000]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat = a_inv + torch.eye(n=n_ped, device=v.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degrees = a_hat.sum(dim=-1).unsqueeze(dim=-1)\n",
    "degs_inv_sqrt = torch.pow(node_degrees, -0.5)\n",
    "degs_inv_sqrt[torch.isinf(degs_inv_sqrt)] = 0\n",
    "norm_degs_matrix = torch.eye(n=n_ped, device=v.device) * degs_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(n=n_ped, device=v.device) - norm_degs_matrix @ a_hat @ norm_degs_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.squeeze(dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((8,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors with the given shapes\n",
    "x = torch.randn(1, 8, 20, 8, 3)\n",
    "A = torch.randn(8, 3, 3)\n",
    "\n",
    "# Perform the einsum operation\n",
    "result = torch.einsum('nkctv,kvw->nctw', x, A)\n",
    "\n",
    "# Print the shape of the result\n",
    "print(result.shape)  # Output: torch.Size([1, 20, 8, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.1220e+00,  4.8355e+00,  6.4208e+00],\n",
       "          [ 5.0591e+00,  3.2090e+00, -1.1434e+01],\n",
       "          [ 1.2014e-01, -6.7630e+00,  7.9955e-01],\n",
       "          [-1.3784e+00,  6.6596e-01, -2.7871e+00],\n",
       "          [-4.2953e+00,  8.3061e+00,  2.6732e+00],\n",
       "          [ 5.2149e+00,  4.8520e-01, -1.3004e+01],\n",
       "          [-1.3339e+00, -2.5211e+00,  5.6034e-01],\n",
       "          [ 2.7685e-01,  1.8114e+00,  4.0560e+00]],\n",
       "\n",
       "         [[ 8.4307e-01,  6.1201e+00,  6.8873e+00],\n",
       "          [ 2.2099e+00,  6.9870e+00,  1.2375e+00],\n",
       "          [-1.5324e+00, -2.0916e+00,  5.8132e-01],\n",
       "          [ 2.9006e+00, -5.0812e+00, -5.1331e+00],\n",
       "          [ 1.2874e+00,  2.1019e-01,  8.9793e-01],\n",
       "          [ 6.3843e+00,  1.8911e-01,  7.3431e+00],\n",
       "          [-1.8209e+00,  3.3201e+00, -4.4816e+00],\n",
       "          [ 4.2718e+00, -1.8875e+00,  2.0647e+00]],\n",
       "\n",
       "         [[-5.7078e+00,  5.1483e+00, -3.8335e+00],\n",
       "          [-4.0552e+00,  7.5836e+00, -4.2818e+00],\n",
       "          [-5.1880e+00,  1.4996e+00,  3.4735e+00],\n",
       "          [ 1.7592e+00, -5.7539e+00,  1.8756e+00],\n",
       "          [ 2.3160e+00,  1.8922e+00, -1.1968e+01],\n",
       "          [ 3.1022e+00,  3.4795e+00,  9.3172e-01],\n",
       "          [-2.7422e+00, -4.3981e+00, -3.4026e+00],\n",
       "          [-2.4377e-01, -1.1450e+00, -4.1672e+00]],\n",
       "\n",
       "         [[ 2.7594e+00, -8.4439e+00, -4.6375e+00],\n",
       "          [-4.9752e-01, -3.2926e+00,  1.5695e+00],\n",
       "          [-1.7464e+00,  1.6526e+00, -6.1795e+00],\n",
       "          [-3.5195e+00,  1.8792e+00,  7.7666e+00],\n",
       "          [-1.3960e+00, -4.1706e+00, -4.7940e+00],\n",
       "          [ 3.7044e+00,  7.3795e-01,  8.1358e+00],\n",
       "          [ 7.3767e+00,  2.2240e+00,  5.9970e-02],\n",
       "          [ 1.3168e+00,  2.6258e-01, -2.8529e+00]],\n",
       "\n",
       "         [[-3.4302e+00,  6.1081e+00,  7.3350e-01],\n",
       "          [ 1.3319e+00,  4.2287e+00,  9.7137e+00],\n",
       "          [-3.6720e+00,  1.7620e+00, -9.9219e+00],\n",
       "          [ 4.3900e+00,  2.3169e+00,  1.5739e-01],\n",
       "          [ 6.9802e+00, -3.6829e+00, -7.8206e+00],\n",
       "          [-8.0817e+00, -1.8189e+00,  4.7702e+00],\n",
       "          [-5.6496e-01, -5.9657e-01,  4.0076e-01],\n",
       "          [ 4.0819e+00,  1.4968e+00, -4.3632e+00]],\n",
       "\n",
       "         [[ 6.1487e-01,  2.6020e+00,  3.3297e-01],\n",
       "          [-9.4265e-01, -8.1781e+00, -4.5685e+00],\n",
       "          [ 2.1918e-01,  2.8159e+00, -2.1507e+00],\n",
       "          [ 5.1057e-01,  7.2092e-02, -2.9559e+00],\n",
       "          [ 3.6423e-01,  2.1466e+00,  3.3571e+00],\n",
       "          [ 2.3903e+00, -3.4476e+00, -2.1519e+00],\n",
       "          [ 5.9916e-02,  3.1035e+00, -5.1172e-01],\n",
       "          [-5.5373e+00, -4.3777e+00,  5.4991e+00]],\n",
       "\n",
       "         [[ 5.8785e-01,  1.6625e+00,  1.6644e+00],\n",
       "          [-1.6632e+00,  1.8479e+00,  5.8090e-01],\n",
       "          [-1.7681e+00, -3.6304e+00,  8.9831e+00],\n",
       "          [-3.6015e+00,  1.1180e+00, -7.5339e-01],\n",
       "          [-7.7028e-01,  3.1210e+00,  5.1686e+00],\n",
       "          [-3.4943e+00,  1.5879e+00, -4.8220e+00],\n",
       "          [ 1.9700e+00,  1.2719e+00,  4.6200e+00],\n",
       "          [ 7.6300e-01, -7.4626e+00,  7.3001e+00]],\n",
       "\n",
       "         [[-2.6687e+00,  2.5150e+00,  1.2256e+01],\n",
       "          [-1.8005e-03, -6.2923e-01, -1.2006e+01],\n",
       "          [ 4.3394e+00,  3.3872e+00,  8.9506e+00],\n",
       "          [ 3.7315e-01, -9.2632e-01,  3.3700e-01],\n",
       "          [ 4.0244e+00,  2.0039e+00,  2.0138e-01],\n",
       "          [ 1.9077e+00, -6.7650e+00,  1.1375e+01],\n",
       "          [ 7.4410e-01, -2.5130e+00,  1.7159e+00],\n",
       "          [ 1.3404e+00, -9.6507e-01,  1.2100e+00]],\n",
       "\n",
       "         [[ 1.0668e+00, -2.1630e+00,  4.9371e+00],\n",
       "          [-1.5881e+00,  2.2954e+00, -6.0330e+00],\n",
       "          [-9.4426e-01,  4.0354e+00,  9.4530e+00],\n",
       "          [ 1.8740e+00,  5.3620e+00,  3.0416e+00],\n",
       "          [-2.9151e-01, -1.1021e+00,  4.2308e+00],\n",
       "          [-2.1548e+00, -1.0683e+00,  6.8293e+00],\n",
       "          [ 2.8369e+00, -2.6138e+00, -1.3354e+01],\n",
       "          [-1.5626e+00, -2.6356e+00,  8.9823e+00]],\n",
       "\n",
       "         [[ 1.8999e+00,  2.7775e+00, -2.6080e+00],\n",
       "          [-5.4675e+00, -1.4517e-01, -1.3557e+00],\n",
       "          [ 6.7739e+00,  3.9321e+00,  5.5372e+00],\n",
       "          [-5.4461e-01,  3.0235e+00, -4.7086e+00],\n",
       "          [ 1.5021e+00, -4.7095e+00,  4.7009e+00],\n",
       "          [-3.7240e+00, -7.0582e+00, -9.2854e+00],\n",
       "          [-2.1031e+00, -1.7576e+00, -9.4684e-01],\n",
       "          [ 1.1084e+00,  4.2974e+00, -4.7515e+00]],\n",
       "\n",
       "         [[-2.4953e+00, -2.6874e+00, -1.2697e+00],\n",
       "          [-3.6823e+00, -3.3838e+00,  1.1347e+00],\n",
       "          [-5.6920e+00, -5.3300e-01, -8.7321e+00],\n",
       "          [ 1.4964e+00, -4.3670e+00,  2.0072e+00],\n",
       "          [ 2.9698e+00,  9.1509e-01, -7.7659e+00],\n",
       "          [ 4.6461e+00,  5.0172e-01, -4.9438e-02],\n",
       "          [ 5.8522e+00,  8.6318e+00,  1.1580e+01],\n",
       "          [-8.1669e-01, -7.9024e+00,  3.1818e+00]],\n",
       "\n",
       "         [[ 1.3290e+00, -4.7977e-01, -1.0576e+01],\n",
       "          [-5.0995e+00,  8.2411e+00,  2.4234e+00],\n",
       "          [ 3.8441e+00, -5.3214e-01, -2.6952e+00],\n",
       "          [ 6.5739e+00,  5.1201e-01, -6.4119e+00],\n",
       "          [ 5.4855e+00, -1.7847e+00, -4.3555e+00],\n",
       "          [-1.0650e+00, -3.7668e+00,  5.0807e+00],\n",
       "          [ 4.9858e+00,  2.1455e+00, -2.2358e+00],\n",
       "          [ 1.9290e+00, -7.9350e-01,  1.9360e-01]],\n",
       "\n",
       "         [[ 7.0295e+00,  8.3920e-02, -3.3671e+00],\n",
       "          [ 2.4578e+00, -4.1957e+00, -1.8303e+01],\n",
       "          [ 2.0792e+00,  8.6008e+00, -9.9207e+00],\n",
       "          [ 1.8075e+00,  2.3088e-01,  1.1658e+00],\n",
       "          [-1.6855e+00, -6.1843e-01,  6.7453e-01],\n",
       "          [-1.8810e+00, -2.1551e+00,  3.0962e+00],\n",
       "          [ 9.0908e+00, -2.1691e+00, -5.7032e+00],\n",
       "          [-1.2631e+00, -1.9316e+00,  8.4512e+00]],\n",
       "\n",
       "         [[ 2.1114e+00,  2.1252e+00, -5.0573e+00],\n",
       "          [-4.4000e+00, -1.9868e+00, -1.3953e+00],\n",
       "          [ 5.5041e-01, -1.0830e+01,  2.5062e+00],\n",
       "          [-2.2015e+00,  7.3653e-02,  2.3824e+00],\n",
       "          [-3.7610e+00, -1.4454e+00, -8.5831e+00],\n",
       "          [ 4.8408e+00,  1.5187e+01, -1.6734e+01],\n",
       "          [ 4.6383e+00,  2.8788e+00, -2.2874e+00],\n",
       "          [ 1.7304e+00, -4.9950e+00, -2.0582e+00]],\n",
       "\n",
       "         [[ 6.8635e-01,  1.9748e+00, -1.4388e+00],\n",
       "          [ 1.6084e+00,  9.4956e+00, -5.9870e+00],\n",
       "          [-1.2902e+00, -4.6246e+00, -6.5413e+00],\n",
       "          [ 8.7334e-01, -1.8919e+00, -2.2068e+00],\n",
       "          [-5.5989e+00, -4.1018e-01,  4.2339e+00],\n",
       "          [ 1.4375e+00, -3.4242e+00,  1.0056e+01],\n",
       "          [-3.2027e+00,  5.3107e+00, -5.1495e+00],\n",
       "          [-1.8572e+00, -6.2511e+00, -6.4868e+00]],\n",
       "\n",
       "         [[ 3.4980e+00, -4.6348e+00,  3.7345e+00],\n",
       "          [ 2.1385e+00,  1.4533e+00, -6.0489e+00],\n",
       "          [ 7.5634e+00,  5.4999e+00,  8.4789e+00],\n",
       "          [-2.6394e+00, -4.6541e+00,  4.1033e-01],\n",
       "          [-1.0651e+00, -3.6990e-01, -3.1644e+00],\n",
       "          [-6.6630e+00, -6.1465e+00,  9.1033e-01],\n",
       "          [-2.9110e+00, -3.7504e+00,  8.6596e+00],\n",
       "          [ 1.4611e+00,  9.5636e-01, -1.3315e+00]],\n",
       "\n",
       "         [[ 4.0051e+00,  8.0925e-01,  1.3078e+01],\n",
       "          [ 1.1486e+00, -2.4171e+00, -9.2679e+00],\n",
       "          [-5.0863e+00, -1.2155e+00,  1.0592e+01],\n",
       "          [ 2.8101e-01, -6.1813e+00,  8.9774e+00],\n",
       "          [-4.4340e+00,  2.7713e+00,  1.2776e+00],\n",
       "          [ 6.3104e-01, -1.7136e+00,  9.0930e+00],\n",
       "          [ 1.1534e+00, -2.0377e+00, -1.3210e+00],\n",
       "          [-5.3451e+00, -8.5997e+00, -9.2847e+00]],\n",
       "\n",
       "         [[ 5.6464e-01,  2.0886e+00,  1.0692e+01],\n",
       "          [-4.0799e-01,  3.0386e+00, -6.9886e+00],\n",
       "          [-4.6924e+00,  5.7217e+00, -2.5583e+00],\n",
       "          [-9.1466e+00, -2.2459e+00,  1.6674e+00],\n",
       "          [-1.4608e+00, -3.9376e+00, -6.2816e+00],\n",
       "          [ 2.5053e+00,  3.3197e+00,  2.2529e+00],\n",
       "          [ 1.4756e-01,  1.3986e+00,  3.7677e+00],\n",
       "          [ 4.2640e+00,  4.1764e-01,  3.7899e+00]],\n",
       "\n",
       "         [[ 1.3656e-01, -4.9124e+00, -2.4331e+00],\n",
       "          [ 6.6847e-01, -3.2743e+00,  1.7543e+00],\n",
       "          [ 4.4930e+00,  3.9067e+00, -7.6753e+00],\n",
       "          [ 3.2498e+00,  3.4404e+00,  5.7976e+00],\n",
       "          [-2.7874e+00, -1.0803e+00,  8.8413e+00],\n",
       "          [-5.7099e-01, -7.7058e+00,  8.0582e+00],\n",
       "          [ 3.8669e+00,  2.9229e-01,  3.8545e+00],\n",
       "          [-3.8755e-01, -2.1569e+00,  6.0852e+00]],\n",
       "\n",
       "         [[-8.1520e-01, -6.0097e+00,  6.6540e+00],\n",
       "          [ 1.4096e+00,  6.8330e+00, -2.4715e+00],\n",
       "          [-1.7073e+00, -2.9468e+00,  1.1237e+00],\n",
       "          [ 1.2558e+00,  1.5462e+00,  7.8204e+00],\n",
       "          [ 3.1838e+00,  3.2228e+00, -1.0012e+01],\n",
       "          [ 5.0332e+00,  5.9644e+00, -2.0451e+00],\n",
       "          [-6.9798e+00, -8.4485e-01, -7.8189e+00],\n",
       "          [ 2.4887e-01, -8.1457e+00,  1.3231e+00]]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class st_gcn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, feature_size, use_mdn=False, stride=1, dropout=0, residual=True):\n",
    "        super(st_gcn, self).__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        self.use_mdn = use_mdn\n",
    "        self.gcn = ConvTemporalGraphical(in_channels, out_channels, kernel_size[1])\n",
    "        self.feature_layer = nn.Linear(feature_size, out_channels)  # new layer for the feature vector\n",
    "\n",
    "        # rest of the __init__ method...\n",
    "\n",
    "    def forward(self, x, A, features):\n",
    "        res = self.residual(x)\n",
    "        x, A = self.gcn(x, A)\n",
    "        features = F.relu(self.feature_layer(features))  # pass the feature vector through the new layer\n",
    "        x = torch.cat((x, features), dim=1)  # concatenate the feature vector with the output of the gcn layer\n",
    "\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        if not self.use_mdn:\n",
    "            x = self.prelu(x)\n",
    "\n",
    "        return x, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "feature = torch.rand(128)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape feature to match the dimensions of x\n",
    "feature = feature.view(1, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 136, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(800,(1,20, 8, 3))\n",
    "feature = torch.randint(800,(128,))\n",
    "feature = feature.view(1, 1, -1, 1)\n",
    "feature = feature.expand(x.size(0), x.size(1), feature.size(2), x.size(3))\n",
    "result = torch.cat([x, feature], dim=2)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]],\n",
       "\n",
       "         [[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]],\n",
       "\n",
       "         [[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]],\n",
       "\n",
       "         [[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]],\n",
       "\n",
       "         [[0.6848, 0.6848, 0.6848],\n",
       "          [0.8411, 0.8411, 0.8411],\n",
       "          [0.3986, 0.3986, 0.3986],\n",
       "          ...,\n",
       "          [0.3444, 0.3444, 0.3444],\n",
       "          [0.3505, 0.3505, 0.3505],\n",
       "          [0.0152, 0.0152, 0.0152]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = feature.expand(x.size(0), x.size(1), feature.size(2), x.size(3))\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([146,  64, 462, 111, 605, 569, 562, 260])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([714, 671, 749,  17, 396, 341, 134, 669, 602,  56, 145, 593, 299, 108,\n",
       "        207,  92, 226, 526, 662, 378, 666, 638,   8,   7, 451, 696, 309,  51,\n",
       "        496, 237, 148, 470, 411, 511, 415, 368,  96, 656, 340, 412, 342, 289,\n",
       "        356, 233, 789, 531, 749, 241, 174,  23, 202, 191, 794, 107,  45, 234,\n",
       "        124, 586,  54, 479, 786, 444, 677, 294, 389, 581, 535, 712, 679, 651,\n",
       "        160,  49, 660, 467, 446, 748, 746, 481, 144, 609, 295,  61, 371, 327,\n",
       "        705, 306, 313, 420, 355, 414,  13, 257, 709, 196, 503, 672, 409, 731,\n",
       "        741, 625, 568, 338, 464, 276,  28, 771, 326, 498, 603, 308, 118, 378,\n",
       "        751, 698, 727, 173, 702, 295,  47, 653, 219,  26, 790,  79, 332, 380,\n",
       "        533, 418])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[0][0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([146,  64, 462, 111, 605, 569, 562, 260, 714, 671, 749,  17, 396, 341,\n",
       "        134, 669, 602,  56, 145, 593, 299, 108, 207,  92, 226, 526, 662, 378,\n",
       "        666, 638,   8,   7, 451, 696, 309,  51, 496, 237, 148, 470, 411, 511,\n",
       "        415, 368,  96, 656, 340, 412, 342, 289, 356, 233, 789, 531, 749, 241,\n",
       "        174,  23, 202, 191, 794, 107,  45, 234, 124, 586,  54, 479, 786, 444,\n",
       "        677, 294, 389, 581, 535, 712, 679, 651, 160,  49, 660, 467, 446, 748,\n",
       "        746, 481, 144, 609, 295,  61, 371, 327, 705, 306, 313, 420, 355, 414,\n",
       "         13, 257, 709, 196, 503, 672, 409, 731, 741, 625, 568, 338, 464, 276,\n",
       "         28, 771, 326, 498, 603, 308, 118, 378, 751, 698, 727, 173, 702, 295,\n",
       "         47, 653, 219,  26, 790,  79, 332, 380, 533, 418])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0][:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[8, 3], edge_index=[2, 72], batch=[8], ptr=[9])\n"
     ]
    }
   ],
   "source": [
    "# Your data\n",
    "obs_data_forward = torch.tensor([[1, 2, 3], \n",
    "                                 [4, 5, 6], \n",
    "                                 [7, 8, 9], \n",
    "                                 [10, 11, 12], \n",
    "                                 [13, 14, 15], \n",
    "                                 [16, 17, 18], \n",
    "                                 [19, 20, 21], \n",
    "                                 [22, 23, 24]], dtype=torch.float)\n",
    "\n",
    "# Your adjacency matrices\n",
    "adjacency_matrices = torch.ones((8, 3, 3))\n",
    "\n",
    "# Convert adjacency matrices to edge_index tensors\n",
    "edge_indices = [adjacency_matrix.nonzero(as_tuple=False).t() for adjacency_matrix in adjacency_matrices]\n",
    "\n",
    "# Create a list of Data objects\n",
    "data_list = [Data(x=obs_data_forward[i].view(1, -1), edge_index=edge_indices[i]) for i in range(8)]\n",
    "\n",
    "# Create a Batch object from the list of Data objects\n",
    "batch = Batch.from_data_list(data_list)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_feature, out_feature, output, heads):\n",
    "        super().__init__()\n",
    "        # First GATConv layer. It takes 'input_feature' as input features and returns 'out_feature' as output features.\n",
    "        # The number of multi-head attentions is 'heads'. Dropout is applied with a rate of 0.6.\n",
    "        self.conv1 = GATConv(input_feature, out_feature, heads, dropout=0.6)\n",
    "        \n",
    "        # Second GATConv layer. It takes 'out_feature * heads' as input features and returns 'output' as output features.\n",
    "        # The number of multi-head attentions is 1. Dropout is applied with a rate of 0.5.\n",
    "        self.conv2 = GATConv(out_feature * heads, output, heads=1 , concat=False, dropout=0.5)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Apply the first GATConv layer and activation function (ELU)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        # Apply dropout\n",
    "        x = F.dropout(x , p=0.5, training=self.training)\n",
    "        # Apply the second GATConv layer\n",
    "        x = self.conv2(x , edge_index)\n",
    "        # Apply dropout\n",
    "        x = F.dropout(x , p=0.5, training=self.training)\n",
    "        # Apply log_softmax and return the result\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 7] (got interval [0, 9])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    265\u001b[0m     index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mindex_select(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim, index)\n\u001b[0;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\AmirKabir\\tez\\eighen trajectory\\project_git\\project\\project_test_cpu\\baseline\\stgcnn\\test_on brige_stgcn.ipynb Cell 35\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m GAT(input_feature\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, out_feature\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, output\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, heads\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Pass the batch of graphs to the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m model(batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Now, 'output' contains the output features of the nodes in the batch of graphs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32md:\\AmirKabir\\tez\\eighen trajectory\\project_git\\project\\project_test_cpu\\baseline\\stgcnn\\test_on brige_stgcn.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Apply the first GATConv layer and activation function (ELU)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39melu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Apply dropout\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AmirKabir/tez/eighen%20trajectory/project_git/project/project_test_cpu/baseline/stgcnn/test_on%20brige_stgcn.ipynb#X46sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x , p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:252\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe usage of \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39msimultaneously is currently not yet supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m form\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[39m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_updater(edge_index, alpha\u001b[39m=\u001b[39;49malpha, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[0;32m    254\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m    255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, alpha\u001b[39m=\u001b[39malpha, size\u001b[39m=\u001b[39msize)\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:523\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[1;34m(self, edge_index, **kwargs)\u001b[0m\n\u001b[0;32m    519\u001b[0m         edge_index, kwargs \u001b[39m=\u001b[39m res\n\u001b[0;32m    521\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(edge_index, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 523\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edge_user_args, edge_index, size,\n\u001b[0;32m    524\u001b[0m                           kwargs)\n\u001b[0;32m    526\u001b[0m edge_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39medge_update\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m    527\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_update(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39medge_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    328\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_size(size, dim, data)\n\u001b[1;32m--> 329\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lift(data, edge_index, dim)\n\u001b[0;32m    331\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[1;32mc:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:269\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    268\u001b[0m     \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m index\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m src\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim):\n\u001b[1;32m--> 269\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncountered an index error. Please ensure that all \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindices in \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m point to valid indices in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe interval [0, \u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim)\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(got interval \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmin())\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax())\u001b[39m}\u001b[39;00m\u001b[39m])\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    275\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;31mIndexError\u001b[0m: Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 7] (got interval [0, 9])"
     ]
    }
   ],
   "source": [
    "# Initialize the GAT model\n",
    "# Assume the input_feature is 3 (as each node has 3 features in obs_data_forward)\n",
    "# and we want the model to output 2 features for each node.\n",
    "# We also set the number of heads in the attention mechanism to 4.\n",
    "model = GAT(input_feature=3, out_feature=64, output=2, heads=4)\n",
    "\n",
    "# Pass the batch of graphs to the model\n",
    "output = model(batch)\n",
    "\n",
    "# Now, 'output' contains the output features of the nodes in the batch of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
